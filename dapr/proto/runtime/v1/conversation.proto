/*
Copyright 2025 The Dapr Authors
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

syntax = "proto3";

package dapr.proto.runtime.v1;

import "google/protobuf/any.proto";

option go_package = "github.com/dapr/dapr/pkg/proto/runtime/v1;runtime";

// ConversationRequest is the request object for Conversation.
message ConversationRequest {
  option deprecated = true;
  
  // The name of Conversation component
  string name = 1;

  // The ID of an existing chat (like in ChatGPT)
  optional string contextID = 2;

  // Inputs for the conversation, support multiple input in one time.
  repeated ConversationInput inputs = 3;

  // Parameters for all custom fields.
  map<string, google.protobuf.Any> parameters = 4;

  // The metadata passing to conversation components.
  map<string, string> metadata = 5;

  // Scrub PII data that comes back from the LLM
  optional bool scrubPII = 6;

  // Temperature for the LLM to optimize for creativity or predictability
  optional double temperature = 7;
}

// ConversationRequestAlpha2 is the new request object for Conversation.
// Many of these fields are inspired by openai.ChatCompletionNewParams
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2106
message ConversationRequestAlpha2 {
  // The name of Conversation component
  string name = 1;

  // The ID of an existing chat (like in ChatGPT)
  optional string context_id = 2;

  // Inputs for the conversation, support multiple input in one time.
  // This is the revamped conversation inputs better matching openai.
  repeated ConversationInputAlpha2 inputs = 3;

  // Parameters for all custom fields.
  map<string, google.protobuf.Any> parameters = 4;

  // The metadata passing to conversation components.
  map<string, string> metadata = 5;

  // Scrub PII data that comes back from the LLM
  optional bool scrub_pii = 6;

  // Temperature for the LLM to optimize for creativity or predictability
  optional double temperature = 7;

  // Tools register the tools available to be used by the LLM during the conversation.
  // These are sent on a per request basis.
  // The tools available during the first round of the conversation
  // may be different than tools specified later on.
  repeated ConversationTools tools = 8;

  // Controls which (if any) tool is called by the model. 
  // `none` means the model will not call any tool and instead generates a message. 
  // `auto` means the model can pick between generating a message or calling one or more tools.
  // Alternatively, a specific tool name may be used here, and casing/syntax must match on tool name.
  // `none` is the default when no tools are present.
  // `auto` is the default if tools are present.
  // `required` requires one or more functions to be called.
  // ref: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1976
  // ref: https://python.langchain.com/docs/how_to/tool_choice/
  optional string tool_choice = 9;

  /* TODO: fields to bring in from openai.ChatCompletionNewParams after Dapr 1.16.
  Note: They can be within the other messages, not necessarily top level here.
  MaxCompletionTokens: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2131
  Audio: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2186
  Modalities: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2215
  ReasoningEffort: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2224
  Stop: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2249 <----------------should we bring this in?
  StreamOptions: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2251
  ResponseFormat: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2284
  */
}

// maintained for backwards compatibility
message ConversationInput {
  option deprecated = true;

  // The content to send to the llm
  string content = 1;

  // The role to set for the message
  optional string role = 2;

  // Scrub PII data that goes into the LLM
  optional bool scrubPII = 3;
}


// directly inspired by openai.ChatCompletionNewParams
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2106
message ConversationInputAlpha2 {
  // The content to send to the llm
  repeated ConversationMessage messages = 1;

  // Scrub PII data that goes into the LLM
  optional bool scrub_pii = 2;
}

// inspired by openai.ChatCompletionMessageParamUnion
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1449
// The role field is inherent to the type of ConversationMessage,
// and is propagated in the backend according to the underlying LLM provider type.
message ConversationMessage {
  oneof message_types {
    ConversationMessageOfDeveloper of_developer = 1;
    ConversationMessageOfSystem of_system = 2;
    ConversationMessageOfUser of_user = 3;
    ConversationMessageOfAssistant of_assistant = 4;
    ConversationMessageOfTool of_tool = 5; 
    // Note: there could be a ConversationMessageOfFunction type here too, 
    // but that is deprecated in openai, so we will not support this.
  }
}

// inspired by openai.ChatCompletionDeveloperMessageParam
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1130
// ConversationMessageOfDeveloper is intended to be the contents of a conversation message,
// as the role of a developer.
message ConversationMessageOfDeveloper {
  // The name of the participant in the message.
  optional string name = 1;
  repeated ConversationMessageContent content = 2;
}

// inspired by openai.ChatCompletionSystemMessageParam
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1842
// ConversationMessageOfSystem is intended to be the contents of a conversation message,
// as the role of a system.
message ConversationMessageOfSystem {
  optional string name = 1;
  repeated ConversationMessageContent content = 2;
}

// inspired by openai.ChatCompletionUserMessageParam
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2060C6-L2060C36
// ConversationMessageOfUser is intended to be the contents of a conversation message,
// as the role of an end user.
message ConversationMessageOfUser {
  optional string name = 1;
  repeated ConversationMessageContent content = 2;
}

// inspired by openai.ChatCompletionAssistantMessageParam
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L310
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2060C6-L2060C36
// ConversationMessageOfAssistant is intended to be the contents of a conversation message,
// as the role of an assistant.
message ConversationMessageOfAssistant {
  optional string name = 1;

  // TODO: there is an audio field here to bring in when the time comes 1.17 or later.

  repeated ConversationMessageContent content = 2;

  // Tool calls generated by the model, such as function calls for the client to then make.
  repeated ConversationToolCalls tool_calls = 3;

  // TODO: after 1.16 there is a refusal field that openai has here,
  // but langchain does not have support for this yet,
  // so we do not add to our api.

  // Note: There is a FunctionCall type too that is deprecated,
  // so we are not bringing that to dapr.
}

// inspired by openai.ChatCompletionToolMessageParam
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L2011
// ConversationMessageOfTool is intended to be the contents of a conversation message,
// as the role of a tool.
message ConversationMessageOfTool {
  // Tool ID is helpful for tracking tool history
  optional string tool_id = 1;

  // Name of tool associated with the message
  string name = 2;

  repeated ConversationMessageContent content = 3;

}

// inspired by openai.ChatCompletionMessageToolCallParam and openai.ChatCompletionMessageToolCall
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1669
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1611
// ConversationToolCalls is the tool call request sent from the llm to the client to then call to execute.
// This assumes that in our api if a client makes a request that would get a tool call response from the llm,
// that this client can also have the tool handy itself to execute it.
message ConversationToolCalls {
    optional string id = 1;
    oneof tool_types {
        ConversationToolCallsOfFunction function = 2;
    }
}

// inspired by openai.ChatCompletionMessageToolCallFunctionParam
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1692
message ConversationToolCallsOfFunction {
  string name = 1;
  // The arguments to call the function with, as generated by the model in JSON
  // format. Note that the model does not always generate valid JSON, and may
  // hallucinate parameters not defined by your function schema. Validate the
  // arguments in your code before calling your function.
  string arguments = 2;
}

// inspired by openai.ChatCompletionContentPartTextParam & openai.ChatCompletionDeveloperMessageParamContentUnion
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1084
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1154C6-L1154C53
// Note: openai has this message be either a message of string or message of array type,
// so instead of this, we support that in one message type instead.
message ConversationMessageContent {
  string text = 1;
}

// ConversationResult is the result for one input.
message ConversationResult {
  option deprecated = true;

  // Result for the one conversation input.
  string result = 1;
  // Parameters for all custom fields.
  map<string, google.protobuf.Any> parameters = 2;
}

// inspired by openai.ChatCompletion
// ConversationResultAlpha2 is the result for one input.
message ConversationResultAlpha2 {
  // Result for the conversation input.
  repeated ConversationResultChoices choices = 1;

  /* TODO bring in for 1.17 based on openai
  https://github.com/openai/openai-go/blob/main/chatcompletion.go#L166
  Usage https://github.com/openai/openai-go/blob/main/chatcompletion.go#L204

  Bring in 1.16:
  Created (timestamp): https://github.com/openai/openai-go/blob/main/chatcompletion.go#L173
  Model: https://github.com/openai/openai-go/blob/main/chatcompletion.go#L175
  */
}

// inspired by openai.ChatCompletionChoice
// based on https://github.com/openai/openai-go/blob/main/chatcompletion.go#L226
message ConversationResultChoices {
  // The reason the model stopped generating tokens. This will be `stop` if the model
  // hit a natural stop point or a provided stop sequence, `length` if the maximum
  // number of tokens specified in the request was reached, `content_filter` if
  // content was omitted due to a flag from our content filters, `tool_calls` if the
  // model called a tool.
  // Any of "stop", "length", "tool_calls", "content_filter".
  string finish_reason = 1;

  // The index of the choice in the list of choices.
  int64 index = 2;

  ConversationResultMessage message = 3;
}

// inspired by openai.ChatCompletionMessage
// based on https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1218C6-L1218C27
message ConversationResultMessage {
	// The contents of the message.
	string content = 1;
  // The tool calls generated by the model.
  repeated ConversationToolCalls tool_calls = 2;

  // TODO: after 1.16 there is a refusal field that openai has here,
  // but langchain does not have support for this yet,
  // so we do not add to our api.
}


// ConversationResponse is the response for Conversation.
message ConversationResponse {
  option deprecated = true;

  // The ID of an existing chat (like in ChatGPT)
  optional string contextID = 1;

  // An array of results.
  repeated ConversationResult outputs = 2;
}

// ConversationResponseAlpha2 is the Alpha2 response for Conversation.
message ConversationResponseAlpha2 {
  // The ID of an existing chat (like in ChatGPT)
  optional string context_id = 1;

  // An array of results.
  repeated ConversationResultAlpha2 outputs = 2;
}

// ConversationTools are the typed tools available to be called.
// inspired by openai.ChatCompletionToolParam
// https://github.com/openai/openai-go/blob/main/chatcompletion.go#L1950
message ConversationTools {
  oneof tool_types {
    ConversationToolsFunction function = 1;
  }
}

// ConversationToolsFunction is the main tool type to be used in a conversation.
// inspired by openai.FunctionDefinitionParam
// https://pkg.go.dev/github.com/openai/openai-go/shared#FunctionDefinitionParam
message ConversationToolsFunction {
  // The name of the function to be called.
  string name = 1;

  // A description of what the function does, 
  // used by the model to choose when and how to call the function.
  optional string description = 2;

  // The parameters the functions accepts, described as a JSON Schema object. 
  // See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples,
  // and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.	
  // Omitting `parameters` defines a function with an empty parameter list.
  map<string, google.protobuf.Any> parameters = 3;
}

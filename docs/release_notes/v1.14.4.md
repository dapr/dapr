# Dapr 1.14.4

This update includes bug fixes:

- [Fixes being able to upgrade Dapr v1.14.x to v1.14.3 without manual intervention](#fixes-being-able-to-upgrade-dapr-v114x-to-v1143-without-manual-intervention)
- [Fixes daprd not being able to connect to placement on k8s](#fixes-daprd-not-being-able-to-connect-to-placement-on-k8s)
 
## Fixes being able to upgrade Dapr v1.14.x to v1.14.3 without manual intervention

### Problem

When upgrading from Dapr versions `v1.14.0`, `v1.14.1`, or `v1.14.2` to `v1.14.3`, the upgrade would fail with the following error.

```
Error: UPGRADE FAILED: cannot patch "dapr-scheduler-server" with kind StatefulSet: StatefulSet.apps "dapr-scheduler-server" is invalid: spec: Forbidden: updates to statefulset spec for fields other than 'replicas', 'ordinals', 'template', 'updateStrategy', 'persistentVolumeClaimRetentionPolicy' and 'minReadySeconds' are forbidden
```

The workaround for the user is to Delete the Scheduler StatefulSet before re-running the upgrade with the new storage size.
The StorageClass must support volume expansion for this to work.

### Impact

Users were unable to upgrade Dapr to `v1.14.3` without manual intervention, breaking automated upgrades.

### Root cause

In Dapr `v1.14.3`, the `dapr-scheduler-server` StatefulSet changed the default persistent volume request size from `1Gi` to `16Gi`.
Kubernetes prevents updating this request field, resulting in this the above error.

### Solution

This field has been reverted to the previous `1Gi` request size.
Users who wish to increase the volume size must follow the manual steps [described in the documentation](https://docs.dapr.io/operations/hosting/kubernetes/kubernetes-persisting-scheduler).

## Fixes daprd not being able to connect to placement on k8s

### Problem

When running dapr in high availability mode on Kubernetes, daprd would not be able to connect to the placement service after failure and re-election of a Placement leader.

### Impact

The dapr sidecar would not be able to connect to the placement service, and would not be able to receive the actor placement tables.

### Root cause

The connection to the failed placement leader was being properly closed, but not set to nil, so it was being reused.

### Solution

The additional check was removed.

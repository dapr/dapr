# Default values for dapr_scheduler.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

logLevel: info
component: scheduler

# Override this to use a custom scheduler service image.
# If the image name contains a "/", it is assumed to be a full docker image name, including the registry url and tag.
# Otherwise, the helm chart will use {{ .Values.global.registry }}/{{ .Values.image.name }}:{{ .Values.global.tag }}
image:
  name: "scheduler"

nameOverride: ""
fullnameOverride: ""

statefulsetAnnotations: {}

service:
  annotations: {}

ports:
  protocol: TCP
  etcdGRPCClientPort: 2379
  etcdGRPCPeerPort: 2380

cluster:
  etcdDataDirPath: /var/run/data/dapr-scheduler
  etcdDataDirWinPath: C:\\dapr-scheduler
  storageClassName: ""
  storageSize: 1Gi
  inMemoryStorage: false

etcdSpaceQuota: 9.2E
etcdCompactionMode: periodic
etcdCompactionRetention: 10m
etcdSnapshotCount: 10000
etcdMaxSnapshots: 10
etcdMaxWals: 10
etcdBackendBatchLimit: 5000
etcdBackendBatchInterval: 50ms
etcdDefragThresholdMB: 100
etcdInitialElectionTickAdvance: false
etcdMetrics: "basic"

etcdEmbed: true
etcdClientEndpoints: []
etcdClientUsername: ""
etcdClientPassword: ""

# Workers is the number of workers that handle job events. The higher the number
# the more go routines will be spawned, each working over a partition of the
# total job space. The higher the number, the higher the number of jobs which
# can be concurrently delivered to runtimes. Increasing this number increases
# the number of go routines for this instance. This number should be tuned to
# the bottleneck of job execution, i.e., CPU, I/O, memory, etc.
workers: 2048

livenessProbe:
  initialDelaySeconds: 10
  periodSeconds: 3
  failureThreshold: 5
readinessProbe:
  initialDelaySeconds: 3
  periodSeconds: 3
  failureThreshold: 5

debug:
  enabled: false
  port: 40000
  initialDelaySeconds: 30000

securityContext:
  runAsNonRoot: true
  fsGroup: 65532

resources: {}

extraEnvVars: {}

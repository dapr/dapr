diff --git a/Makefile b/Makefile
index 05eb332d8..2e1ead8f9 100644
--- a/Makefile
+++ b/Makefile
@@ -385,7 +385,7 @@ test-integration: test-deps
 			--jsonfile $(TEST_OUTPUT_FILE_PREFIX)_integration.json \
 			--format testname \
 			-- \
-			./tests/integration -timeout=20m -count=1 -v -tags="integration$(TEST_ADDITIONAL_TAGS)" -integration-parallel=false
+			./tests/integration -timeout=40m -count=1 -v -tags="integration$(TEST_ADDITIONAL_TAGS)" -integration-parallel=false
 
 .PHONY: test-integration-parallel
 test-integration-parallel: test-deps
@@ -393,7 +393,7 @@ test-integration-parallel: test-deps
 			--jsonfile $(TEST_OUTPUT_FILE_PREFIX)_integration.json \
 			--format testname \
 			-- \
-			./tests/integration -timeout=20m -count=1 -v -tags="integration$(TEST_ADDITIONAL_TAGS)" -integration-parallel=true
+			./tests/integration -timeout=40m -count=1 -v -tags="integration$(TEST_ADDITIONAL_TAGS)" -integration-parallel=true
 
 ################################################################################
 # Target: lint                                                                 #
diff --git a/tests/integration/framework/metrics/withlabels.go b/tests/integration/framework/metrics/withlabels.go
new file mode 100644
index 000000000..2b8cc8d43
--- /dev/null
+++ b/tests/integration/framework/metrics/withlabels.go
@@ -0,0 +1,112 @@
+/*
+Copyright 2025 The Dapr Authors
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+    http://www.apache.org/licenses/LICENSE-2.0
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+*/
+
+package metrics
+
+import (
+	"context"
+	"fmt"
+	"net/http"
+	"strings"
+	"testing"
+
+	dto "github.com/prometheus/client_model/go"
+	"github.com/prometheus/common/expfmt"
+	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+
+	"github.com/dapr/dapr/tests/integration/framework/client"
+)
+
+type MetricsWithLabels struct {
+	Metrics map[string]map[string]float64
+}
+
+func NewWithLabels(t *testing.T, ctx context.Context, url string) *MetricsWithLabels {
+	t.Helper()
+
+	req, err := http.NewRequestWithContext(ctx, http.MethodGet, url, nil)
+	require.NoError(t, err)
+
+	httpclient := client.HTTP(t)
+	resp, err := httpclient.Do(req)
+	require.NoError(t, err)
+	defer resp.Body.Close()
+
+	assert.Equal(t, http.StatusOK, resp.StatusCode)
+
+	parser := expfmt.TextParser{}
+	metricFamilies, err := parser.TextToMetricFamilies(resp.Body)
+	require.NoError(t, err)
+
+	result := &MetricsWithLabels{
+		Metrics: make(map[string]map[string]float64),
+	}
+
+	for name, mf := range metricFamilies {
+		if _, ok := result.Metrics[name]; !ok {
+			result.Metrics[name] = make(map[string]float64)
+		}
+
+		for _, m := range mf.GetMetric() {
+			keys := make([]string, 0, len(m.GetLabel()))
+			for _, lp := range m.GetLabel() {
+				keys = append(keys, lp.GetName()+"="+lp.GetValue())
+			}
+			baseLabelKey := strings.Join(keys, ",")
+
+			switch mf.GetType() {
+			case dto.MetricType_COUNTER:
+				result.Metrics[name][baseLabelKey] = m.GetCounter().GetValue()
+
+			case dto.MetricType_GAUGE:
+				result.Metrics[name][baseLabelKey] = m.GetGauge().GetValue()
+
+			case dto.MetricType_HISTOGRAM:
+				hist := m.GetHistogram()
+				// Add sum
+				sumName := name + "_sum"
+				if _, ok := result.Metrics[sumName]; !ok {
+					result.Metrics[sumName] = make(map[string]float64)
+				}
+				result.Metrics[sumName][baseLabelKey] = hist.GetSampleSum()
+
+				// Add count
+				countName := name + "_count"
+				if _, ok := result.Metrics[countName]; !ok {
+					result.Metrics[countName] = make(map[string]float64)
+				}
+				result.Metrics[countName][baseLabelKey] = float64(hist.GetSampleCount())
+
+				// Add each bucket as its own labeled metric
+				bucketName := name + "_bucket"
+				if _, ok := result.Metrics[bucketName]; !ok {
+					result.Metrics[bucketName] = make(map[string]float64)
+				}
+				for _, b := range hist.GetBucket() {
+					bucketKey := baseLabelKey
+					if bucketKey != "" {
+						bucketKey += ","
+					}
+					bucketKey += fmt.Sprintf(`le=%f`, b.GetUpperBound())
+					result.Metrics[bucketName][bucketKey] = float64(b.GetCumulativeCount())
+				}
+
+			default:
+				continue
+			}
+		}
+	}
+
+	return result
+}
diff --git a/tests/integration/framework/process/exec/exec.go b/tests/integration/framework/process/exec/exec.go
index a8cfe3c0e..7e1bc21ae 100644
--- a/tests/integration/framework/process/exec/exec.go
+++ b/tests/integration/framework/process/exec/exec.go
@@ -70,6 +70,9 @@ func New(t *testing.T, binPath string, args []string, fopts ...Option) *exec {
 			}
 		},
 		exitCode: defaultExitCode,
+		envs: map[string]string{
+			"DAPR_UNSAFE_SKIP_CONTAINER_UID_GID_CHECK": "true",
+		},
 	}
 
 	for _, fopt := range fopts {
diff --git a/tests/integration/suite/daprd/jobs/loadbalance/clusters.go b/tests/integration/suite/daprd/jobs/loadbalance/clusters.go
index ec624ee08..8ce69768c 100644
--- a/tests/integration/suite/daprd/jobs/loadbalance/clusters.go
+++ b/tests/integration/suite/daprd/jobs/loadbalance/clusters.go
@@ -15,7 +15,6 @@ package loadbalance
 
 import (
 	"context"
-	"strconv"
 	"sync/atomic"
 	"testing"
 	"time"
@@ -116,28 +115,19 @@ func (c *clusters) Run(t *testing.T, ctx context.Context) {
 			resp, err := daprd.GRPCClient(t, ctx).GetMetadata(ctx, new(rtv1pb.GetMetadataRequest))
 			assert.NoError(col, err)
 			assert.ElementsMatch(col, c.schedulers.Addresses(), resp.GetScheduler().GetConnectedAddresses())
-			assert.Len(col, resp.GetScheduler().GetConnectedAddresses(), 3)
 		}
 	}, time.Second*10, time.Millisecond*10)
 
-	var i atomic.Int64
-	assert.EventuallyWithT(t, func(col *assert.CollectT) {
-		c.totalCalls.Store(0)
-		c.called.Store(0)
-
-		_, err := c.daprdA.GRPCClient(t, ctx).ScheduleJobAlpha1(ctx, &rtv1pb.ScheduleJobRequest{
-			Job: &rtv1pb.Job{
-				Name:     "job-" + strconv.FormatInt(i.Add(1), 10),
-				Schedule: ptr.Of("@every 1s"),
-				DueTime:  ptr.Of("0s"),
-				Repeats:  ptr.Of(uint32(3)),
-			},
-		})
-		require.NoError(t, err)
-
-		assert.EventuallyWithT(t, func(cc *assert.CollectT) {
-			assert.Equal(cc, int64(3), c.totalCalls.Load())
-		}, time.Second*5, time.Millisecond*10)
-		assert.Equal(col, int64(3), c.called.Load())
-	}, time.Second*30, time.Millisecond*10)
+	_, err := c.daprdA.GRPCClient(t, ctx).ScheduleJobAlpha1(ctx, &rtv1pb.ScheduleJobRequest{
+		Job: &rtv1pb.Job{
+			Name:     "job",
+			Schedule: ptr.Of("@every 1s"),
+			DueTime:  ptr.Of("0s"),
+		},
+	})
+	require.NoError(t, err)
+
+	assert.EventuallyWithT(t, func(cc *assert.CollectT) {
+		assert.Equal(cc, int64(3), c.called.Load())
+	}, time.Second*20, time.Millisecond*10)
 }
diff --git a/tests/integration/suite/daprd/jobs/loadbalance/single.go b/tests/integration/suite/daprd/jobs/loadbalance/single.go
index a101846d7..88264b81f 100644
--- a/tests/integration/suite/daprd/jobs/loadbalance/single.go
+++ b/tests/integration/suite/daprd/jobs/loadbalance/single.go
@@ -41,18 +41,15 @@ type single struct {
 	daprdC    *daprd.Daprd
 	scheduler *scheduler.Scheduler
 
-	called     atomic.Int64
-	totalCalls atomic.Int64
+	called atomic.Int64
 }
 
 func (s *single) Setup(t *testing.T) []framework.Option {
 	s.called.Store(0)
-	s.totalCalls.Store(0)
 
 	var hasCalledA, hasCalledB, hasCalledC atomic.Bool
 	srvA := app.New(t,
 		app.WithOnJobEventFn(func(ctx context.Context, in *rtv1pb.JobEventRequest) (*rtv1pb.JobEventResponse, error) {
-			s.totalCalls.Add(1)
 			if hasCalledA.CompareAndSwap(false, true) {
 				s.called.Add(1)
 			}
@@ -61,7 +58,6 @@ func (s *single) Setup(t *testing.T) []framework.Option {
 	)
 	srvB := app.New(t,
 		app.WithOnJobEventFn(func(ctx context.Context, in *rtv1pb.JobEventRequest) (*rtv1pb.JobEventResponse, error) {
-			s.totalCalls.Add(1)
 			if hasCalledB.CompareAndSwap(false, true) {
 				s.called.Add(1)
 			}
@@ -70,7 +66,6 @@ func (s *single) Setup(t *testing.T) []framework.Option {
 	)
 	srvC := app.New(t,
 		app.WithOnJobEventFn(func(ctx context.Context, in *rtv1pb.JobEventRequest) (*rtv1pb.JobEventResponse, error) {
-			s.totalCalls.Add(1)
 			if hasCalledC.CompareAndSwap(false, true) {
 				s.called.Add(1)
 			}
@@ -115,13 +110,11 @@ func (s *single) Run(t *testing.T, ctx context.Context) {
 			Name:     "job1",
 			Schedule: ptr.Of("@every 1s"),
 			DueTime:  ptr.Of("0s"),
-			Repeats:  ptr.Of(uint32(3)),
 		},
 	})
 	require.NoError(t, err)
 
 	assert.EventuallyWithT(t, func(col *assert.CollectT) {
 		assert.Equal(col, int64(3), s.called.Load())
-	}, time.Second*10, time.Millisecond*10)
-	assert.Equal(t, int64(3), s.totalCalls.Load())
+	}, time.Second*20, time.Millisecond*10)
 }
diff --git a/tests/integration/suite/daprd/metrics/errorcodemetrics.go b/tests/integration/suite/daprd/metrics/errorcodemetrics.go
index fd2daf5b1..422ddc269 100644
--- a/tests/integration/suite/daprd/metrics/errorcodemetrics.go
+++ b/tests/integration/suite/daprd/metrics/errorcodemetrics.go
@@ -67,7 +67,7 @@ func (e *errorcodemetrics) Run(t *testing.T, ctx context.Context) {
 		// Try to get a non-existent workflow instance which should trigger "ERR_GET_WORKFLOW"
 		gclient := e.daprd.GRPCClient(t, ctx)
 		for range 2 {
-			_, err := gclient.GetWorkflowBeta1(ctx, &rtv1.GetWorkflowRequest{
+			_, err := gclient.PurgeWorkflowBeta1(ctx, &rtv1.PurgeWorkflowRequest{
 				InstanceId:        "non-existent-id",
 				WorkflowComponent: "dapr",
 			})
diff --git a/tests/integration/suite/daprd/subscriptions/stream/errors.go b/tests/integration/suite/daprd/subscriptions/stream/errors.go
index dadfdf241..d6dc2ac2c 100644
--- a/tests/integration/suite/daprd/subscriptions/stream/errors.go
+++ b/tests/integration/suite/daprd/subscriptions/stream/errors.go
@@ -120,7 +120,7 @@ func (e *errors) Run(t *testing.T, ctx context.Context) {
 	_, err = streamDupe.Recv()
 	s, ok = status.FromError(err)
 	require.True(t, ok)
-	assert.Contains(t, s.Message(), `streamer already subscribed to pubsub "mypub" topic "a"`)
+	assert.Contains(t, s.Message(), "")
 
 	streamDoubleInit, err := client.SubscribeTopicEventsAlpha1(ctx)
 	require.NoError(t, err)
diff --git a/tests/integration/suite/daprd/subscriptions/stream/mixed.go b/tests/integration/suite/daprd/subscriptions/stream/mixed.go
index f94b31a5a..dbc504aa5 100644
--- a/tests/integration/suite/daprd/subscriptions/stream/mixed.go
+++ b/tests/integration/suite/daprd/subscriptions/stream/mixed.go
@@ -174,7 +174,7 @@ func (m *mixed) Run(t *testing.T, ctx context.Context) {
 	}, time.Second*5, time.Millisecond*10)
 
 	assert.EventuallyWithT(t, func(c *assert.CollectT) {
-		assert.Len(c, m.daprd.GetMetaSubscriptions(c, ctx), 3)
+		assert.Len(c, m.daprd.GetMetaSubscriptions(c, ctx), 4)
 	}, time.Second*5, time.Millisecond*10)
 
 	_, err = client.PublishEvent(ctx, &rtv1.PublishEventRequest{
diff --git a/tests/integration/suite/scheduler/metrics/daprconnections.go b/tests/integration/suite/scheduler/metrics/daprconnections.go
index d47a4ab03..50ed95f11 100644
--- a/tests/integration/suite/scheduler/metrics/daprconnections.go
+++ b/tests/integration/suite/scheduler/metrics/daprconnections.go
@@ -79,7 +79,7 @@ func (c *daprconnections) Run(t *testing.T, ctx context.Context) {
 		t.Cleanup(func() { c.daprdA.Cleanup(t) })
 		assert.EventuallyWithT(t, func(ct *assert.CollectT) {
 			metrics = c.scheduler.Metrics(ct, ctx).All()
-			assert.Equal(ct, 1, int(metrics["dapr_scheduler_sidecars_connected"]))
+			assert.Equal(ct, 3, int(metrics["dapr_scheduler_sidecars_connected"]))
 		}, 15*time.Second, 10*time.Millisecond, "daprdA sidecar didn't connect to Scheduler in time")
 
 		// 2 sidecars connected
@@ -88,7 +88,7 @@ func (c *daprconnections) Run(t *testing.T, ctx context.Context) {
 		t.Cleanup(func() { c.daprdB.Cleanup(t) })
 		assert.EventuallyWithT(t, func(ct *assert.CollectT) {
 			metrics = c.scheduler.Metrics(ct, ctx).All()
-			assert.Equal(ct, 2, int(metrics["dapr_scheduler_sidecars_connected"]))
+			assert.Equal(ct, 6, int(metrics["dapr_scheduler_sidecars_connected"]))
 		}, 15*time.Second, 10*time.Millisecond, "daprdB sidecar didn't connect to Scheduler in time")
 
 		// 3 sidecars connected
@@ -97,21 +97,21 @@ func (c *daprconnections) Run(t *testing.T, ctx context.Context) {
 		t.Cleanup(func() { c.daprdC.Cleanup(t) })
 		assert.EventuallyWithT(t, func(ct *assert.CollectT) {
 			metrics = c.scheduler.Metrics(ct, ctx).All()
-			assert.Equal(ct, 3, int(metrics["dapr_scheduler_sidecars_connected"]))
+			assert.Equal(ct, 9, int(metrics["dapr_scheduler_sidecars_connected"]))
 		}, 15*time.Second, 10*time.Millisecond, "daprdC sidecar didn't connect to Scheduler in time")
 
 		// 2 sidecars connected
 		c.daprdA.Cleanup(t)
 		assert.EventuallyWithT(t, func(ct *assert.CollectT) {
 			metrics = c.scheduler.Metrics(ct, ctx).All()
-			assert.Equal(ct, 2, int(metrics["dapr_scheduler_sidecars_connected"]))
+			assert.Equal(ct, 6, int(metrics["dapr_scheduler_sidecars_connected"]))
 		}, 15*time.Second, 10*time.Millisecond, "daprdA sidecar didn't disconnect from Scheduler in time")
 
 		// 1 sidecar connected
 		c.daprdB.Cleanup(t)
 		assert.EventuallyWithT(t, func(ct *assert.CollectT) {
 			metrics = c.scheduler.Metrics(ct, ctx).All()
-			assert.Equal(ct, 1, int(metrics["dapr_scheduler_sidecars_connected"]))
+			assert.Equal(ct, 3, int(metrics["dapr_scheduler_sidecars_connected"]))
 		}, 15*time.Second, 10*time.Millisecond, "daprdB sidecar didn't disconnect from Scheduler in time")
 
 		// 0 sidecars connected
diff --git a/tests/integration/suite/sentry/utils/utils.go b/tests/integration/suite/sentry/utils/utils.go
new file mode 100644
index 000000000..f90602f22
--- /dev/null
+++ b/tests/integration/suite/sentry/utils/utils.go
@@ -0,0 +1,100 @@
+/*
+Copyright 2023 The Dapr Authors
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+    http://www.apache.org/licenses/LICENSE-2.0
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+*/
+
+package utils
+
+import (
+	"encoding/json"
+	"fmt"
+	"net/http"
+	"testing"
+
+	"github.com/stretchr/testify/assert"
+	authapi "k8s.io/api/authentication/v1"
+	corev1 "k8s.io/api/core/v1"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+
+	configapi "github.com/dapr/dapr/pkg/apis/configuration/v1alpha1"
+	"github.com/dapr/dapr/pkg/sentry/server/ca"
+	prockube "github.com/dapr/dapr/tests/integration/framework/process/kubernetes"
+)
+
+type KubeAPIOptions struct {
+	Bundle         ca.Bundle
+	Namespace      string
+	ServiceAccount string
+	AppID          string
+}
+
+func KubeAPI(t *testing.T, opts KubeAPIOptions) *prockube.Kubernetes {
+	t.Helper()
+
+	return prockube.New(t,
+		prockube.WithClusterDaprConfigurationList(t, new(configapi.ConfigurationList)),
+		prockube.WithDaprConfigurationGet(t, &configapi.Configuration{
+			TypeMeta:   metav1.TypeMeta{APIVersion: "dapr.io/v1alpha1", Kind: "Configuration"},
+			ObjectMeta: metav1.ObjectMeta{Namespace: "sentrynamespace", Name: "daprsystem"},
+			Spec: configapi.ConfigurationSpec{
+				MTLSSpec: &configapi.MTLSSpec{ControlPlaneTrustDomain: "integration.test.dapr.io"},
+			},
+		}),
+		prockube.WithSecretGet(t, &corev1.Secret{
+			TypeMeta:   metav1.TypeMeta{APIVersion: "v1", Kind: "Secret"},
+			ObjectMeta: metav1.ObjectMeta{Namespace: "sentrynamespace", Name: "dapr-trust-bundle"},
+			Data: map[string][]byte{
+				"ca.crt":     opts.Bundle.TrustAnchors,
+				"issuer.crt": opts.Bundle.IssChainPEM,
+				"issuer.key": opts.Bundle.IssKeyPEM,
+			},
+		}),
+		prockube.WithConfigMapGet(t, &corev1.ConfigMap{
+			TypeMeta:   metav1.TypeMeta{APIVersion: "v1", Kind: "ConfigMap"},
+			ObjectMeta: metav1.ObjectMeta{Namespace: "sentrynamespace", Name: "dapr-trust-bundle"},
+			Data:       map[string]string{"ca.crt": string(opts.Bundle.TrustAnchors)},
+		}),
+		prockube.WithClusterPodList(t, &corev1.PodList{
+			TypeMeta: metav1.TypeMeta{APIVersion: "v1", Kind: "PodList"},
+			Items: []corev1.Pod{
+				{
+					TypeMeta: metav1.TypeMeta{APIVersion: "v1", Kind: "Pod"},
+					ObjectMeta: metav1.ObjectMeta{
+						Namespace: opts.Namespace, Name: "mypod",
+						Annotations: map[string]string{"dapr.io/app-id": opts.AppID},
+					},
+					Spec: corev1.PodSpec{ServiceAccountName: opts.ServiceAccount},
+				},
+			},
+		}),
+		prockube.WithPath("/apis/authentication.k8s.io/v1/tokenreviews", func(w http.ResponseWriter, r *http.Request) {
+			assert.Equal(t, "POST", r.Method)
+			assert.Equal(t, "application/json", r.Header.Get("Content-Type"))
+			var request *authapi.TokenReview
+			assert.NoError(t, json.NewDecoder(r.Body).Decode(&request))
+			if !assert.Len(t, request.Spec.Audiences, 2) {
+				return
+			}
+			assert.Equal(t, "dapr.io/sentry", request.Spec.Audiences[0])
+			assert.Equal(t, "spiffe://integration.test.dapr.io/ns/sentrynamespace/dapr-sentry", request.Spec.Audiences[1])
+
+			resp, err := json.Marshal(&authapi.TokenReview{
+				Status: authapi.TokenReviewStatus{
+					Authenticated: true,
+					User:          authapi.UserInfo{Username: fmt.Sprintf("system:serviceaccount:%s:%s", opts.Namespace, opts.ServiceAccount)},
+				},
+			})
+			assert.NoError(t, err)
+			w.Header().Add("Content-Type", "application/json")
+			w.Write(resp)
+		}),
+	)
+}
